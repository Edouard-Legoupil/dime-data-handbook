%------------------------------------------------

\begin{fullwidth}
Sampling, randomization, and power calculations are the core elements of experimental design.
Sampling and randomization determine which units are observed and in which states.
Each of these processes introduces ``noise'' into the final estimates of effect sizes:
sampling noise produces some probability of chance selection of units that will produce wrong estimates;
randomization noise produces some probabilty of chance placement of units into treatment arms that does the same.
Power calculation is the method by which these probabilities of error are meaningfully assessed.
Good experimental design has high power -- a low likelihood that these noise parameters meaningfully affected estimates of treatment effects.

Not all studies are capable of achieving traditionally high power:
the sampling or treatment universe may simply be fundamentally too noisy.
This may be especially true for novel or small-scale studies --
things that have never been tried before may be hard to fund or execute at scale.
What is important is that every study includes reasonable estimates of its power,
so that the evidentiary value of the result can be honestly assessed.
Demonstrating that sampling and randomization were taken seriously into consideration
before going to field lends credibility to any research study.
Using these tools to execute the most highly-powered experiments possible
is a responsible and ethical use of donor and client resources,
and maximizes the likelihood that reported effect sizes are accurate.
\end{fullwidth}

%------------------------------------------------
\section{Reproducibility}

Reproducibility in statistical programming is absolutely essential.
This section is a short introduction to ensuring that code
which generates randomized outputs is reproducible.
There are three key inputs to assuring reproducibility:
versioning, sorting, and seeding.
Without these, other people running your code may get very different results in the future.

Versioning means using the same version of the software.
\marginnote{All versions of Stata above version 13 currently operate identically on all platforms.
In the past, differences between operating systems could also cause replicability issues,
but PCs and Macs currently use the same chip architecture.}
If anything is different, the underlying randomization algorithm may have changed,
and it will be impossible to recover the original result.
In Stata, the \texttt{version} command ensures that the software algorithm is fixed.
The \texttt{ieboilstart} command has built-in functionality to support this requirement.

Sorting means that the actual data that the random process is run on is fixed.
Most random outcomes have as their basis an algorithmic sequence of pseudorandom numbers.
This means that if the start point is set, the full sequence of numbers will not change.
\marginnote{A corollary of this is that the underlying data must be unchanged between runs:
to ensure that the dataset is fixed, you must make a \texttt{LOCKED} copy of it at runtime.}
However, if you re-run the process with the dataset in a different order,
the same numbers will get assigned to different units, and the randomization will turn out different.
In Stata, \texttt{isid [id\_variable], sort} will ensure that order is fixed over repeat runs.

Seeding means manually setting the start-point of the randomization algorithm.
If the randomization seed is not set, then the pseudorandom algorithm will pick up where it left off.
By setting the seed, you force it to restart from a set point.
In Stata, \texttt{set seed [seed]} will accomplish this.

\marginnote[2\baselineskip]{This code loads and sets up the \texttt{auto.dta} dataset
for any random process. Note the three components: versioning, sorting, and seeding.
Why are \texttt{check1} and \texttt{check3} the same? Why is \texttt{check2} different?}

\VerbatimInput[frame=lines,numbers=left,label=replicability.do]{./code/replicability.do}

Commands like \texttt{bys:} and \texttt{merge} will re-sort your data as part of their execution,
and other commands may alter the randomization seed without you realizing it.
Any of these things will cause the output to fail to replicate.
Therefore, each randomization process should be independently executed
to ensure that these three rules are followed.
Before shipping the results of a randomization,
save the outputs of the randomization in a temporary location,
re-run the file, and use \texttt{cf \_all using [dataset]} targeting the saved file.
If there are any differences, the process has not reproduced,
and \texttt{cf} will return an error.

%------------------------------------------------
\section{Sampling}

Sampling is the process of selecting units of observation from a master list for survey data collection.
This list may be called a ``sampling universe'', a ``listing frame'', or something similar.
We refer to it as a \textbf{master data set} because it is the authoritative source
for the existence and fixed characteristics of each of the units that may be surveyed.
If data collected in the field contradicts the master data,
the master data always dominates (unless the field data is so inconsistent that a master update is necessary).
Most importantly, the master data set indicates how many individuals are eligible for sampling and surveying,
and therefore contains statistical information about the likelihood that each will be chosen.

The fundamental contribution of sampling to the power of a research design is this:
if you randomly sample a set number of observations from a set frame,
there are a large -- but fixed -- number of sample sets which you may draw.
From any large group, you can find some possible sample sets
that have higher-than-average values of some measure;
similarly, you can find some sets that have lower-than-average values.
The variation of these values across the range of all possible sample sets is what creates
\textbf{sampling noise}, the uncertainty in statistical estimates caused by sampling.

Portions of this noise can be reduced through design.
\marginnote{In general, all sampling requires \textbf{inverse probability weights}.
These are conceptually simple in that the weights for each individual must be precisely the inverse of the probability
with which that individual is included in the sample, but may be practically difficult to calculate for complex methods.
When the sampling probability is uniform, all the weights are equal to one.}
Sampling can be structured such that subgroups are guaranteed to appear in a sample:
that is, you can pick ``half the level one facilities and half the level two facilities'' instead of
``half of all facilities''. The key here is that, \textit{for each facility},
the probability of being chosen remains the same -- 0.5.
By contrast, a sampling design that chooses unbalanced proportions of subgroups
has changed the probability that a given individual is included in the sample,
and needs to be reweighted in case you want to calculate overall average statistics.

In general, for any underlying distribution, the Central Limit Theorem implies that
the distribution of variation across the possible samples is exactly normal.
Therefore, we can use what are called ``asymptotic'' standard errors
to express how far away from the true population parameters our estimates are likely to be.
These standard errors can be calculated with only two datapoints:
the sample size and the standard deviation of the value in the chosen sample.

\marginnote[2\baselineskip]{This Stata code executes a very simple illustration of sampling noise.
It also demonstrates how to take a uniform-probability random sample from a population using the \texttt{sample} command.
\linebreak \linebreak
More advanced sampling techniques, such as clustering and stratification,
are in practice identical in implementation to the randomization section that follows --
instead of creating a \texttt{treatment} variable, create a \texttt{sample} variable.}

\VerbatimInput[frame=lines,numbers=left,label=simple-sample.do]{./code/simple-sample.do}

%------------------------------------------------
\section{Randomization}

%------------------------------------------------
\section{Power}

%------------------------------------------------
