%-----------------------------------------------------------------------------------------------

\begin{fullwidth}
Research design is the process of structuring field work
-- both experimental design and data collection --
that will answer a specific research question.
You don't need to be an expert in this,
and there are lots of good resources out there
that focus on designing interventions and evaluations
as well as on econometric approaches.
This section will present a brief overview
of the most common methods that are used in development research.
Specifically, we will introduce you to several ``causal inference'' methods
that are frequently used to understand the impact of real development programs.
The intent is for you to obtain an understanding of
the way in which each method constructs treatment and control groups,
the data structures needed to estimate the corresponding effects,
and any available code tools that will assist you in this process.

This is important to understand before going into the field for several reasons.
If you do not understand how to calculate the correct estimator for your study,
you will not be able to assess the power of your research design.
You will also be unable to make tradeoffs in the field
when you inevitable have to allocate scarce resources
between tasks like maximizing sample size
and ensuring follow-up with specific individuals.
You will save a lot of time by understanding the way
your data needs to be organized and set up as it comes in
before you will be able to calculate meaningful results.
Just as importantly, understanding each of these approaches
will allow you to keep your eyes open for research opportunities:
many of the most interesting projects occur because people in the field
recognize the opportunity to implement one of these methods on the fly
in response to an unexpected event in the field.
While somewhat more conceptual than practical,
a basic understanding of your project's chosen approach will make you
much more effective at the analytical part of your work.
\end{fullwidth}

%-----------------------------------------------------------------------------------------------
%-----------------------------------------------------------------------------------------------

\section{Causality, inference, and identification}

The primary goal of research design is to establish \textbf{identification}
for a parameter of interest -- that is, to demonstrate
a source of variation in a particular input that has no other possible channel
to alter a particular outcome, in order to assert that some change in that outcome
was caused by that change in the input.
  \index{identification}
When we are discussing the types of inputs commonly referred to as
``programs'' or ``interventions'', we are typically attempting to obtain estimates
of a program-specific \textbf{treatment effect}, or the change in outcomes
directly attributable to exposure to what we call the \textbf{treatment}.\cite{abadie2018econometric}
  \index{treatment effect}
When identification is believed, then we can say with confidence
that our estimate of the treatment effect would,
with an infinite amount of data,
give us a precise estimate of that treatment effect.
Under this condition, we can proceed to draw evidence from the limited samples we have access to,
using statistical techniques to express the uncertainty of not having infinite data.
Without identification, we cannot say that the estimate would be accurate,
even with unlimited data, and therefore cannot associate it to the treatment
in the small samples that we typically have access to.
Conversely, more data is not a substitute for a well-identified experimental design.
Therefore it is important to understand how exactly your study
identifies its estimate of treatment effects,
so you can calculate and interpret those estimates appropriately.
All the study designs we discuss here use the \textbf{potential outcomes} framework
to compare the a group that recieved some treatment to another, counterfactual group.
Each of these types of approaches can be used in two contexts:
\textbf{experimental} designs, in which the research team
is directly responsible for creating the variation in treatment,
and \textbf{quasi-experimental} designs, in which the team
identifies a ``natural'' source of variation and uses it for identification.
Neither type of approach is implicitly better or worse,
and both are capable of achieving effect identification under different contexts.

%-----------------------------------------------------------------------------------------------
\subsection{Estimating treatment effects using control groups}

The key assumption behind estimating treatment effects is that every
person, facility, or village (or whatever the unit of intervention is)
has two possible states: their outcomes if they do not recieve some treatment
and their outcomes if they do recieve that treatment.
Each unit's treatment effect is the individual difference between these two states,
and the \textbf{average treatment effect (ATE)} is the average of all of
these differences across the potentially treated population.
  \index{average treatment effect}
This is the most common parameter that research designs will want to estimate.
In most designs, the goal is to establish a ``counterfactual scenario'' for the treatment group
with which outcomes can be directly compared.
There are several resources that provide more or less mathematically intensive
approaches to understanding how various methods to his.
\textit{Causal Inference} and \textit{Causal Inference: The Mixtape}
provides a detailed practical introduction to and history of
each of these methods.\sidenote{
  \url{https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/}
  \\ \noindent \url{http://scunning.com/cunningham_mixtape.pdf}}
\textit{Mostly Harmless Econometrics} and \textit{Mastering Metrics}
are canonical treatments of the mathematics behind all econometric approaches.\sidenote{
  \url{https://www.researchgate.net/publication/51992844\_Mostly\_Harmless\_Econometrics\_An\_Empiricist's\_Companion}
  \\ \noindent \url{http://assets.press.princeton.edu/chapters/s10363.pdf}}

Intuitively, the problem is as follows: we can never observe the same unit
in both their treated and untreated states simultaneously,
so measuring and averaging these effects directly is impossible.\sidenote{
  \url{http://www.stat.columbia.edu/~cook/qr33.pdf}}
Instead, we typically make inferences from samples.
\textbf{Causal inference} methods are those in which we are able to estimate the
average treatment effect without observing individual-level effects,
but can obtain it from some comparison of averages with a \textbf{control} group.
  \index{causal inference}\index{control group}
Every research design is based around a way of comparing another set of observations --
the ``control'' observations -- against the treatment group.
They all work to establish that the control observations would have been
identical \textit{on average} to the treated group in the absence of the treatment.
Then, the mathematical properties of averages implies that the calculated
difference in averages is equivalent to the average difference:
exactly the parameter we are seeking to estimate.
Therefore, almost all designs can be accurately described
as a series of between-group comparisons.\sidenote{
  \url{http://nickchk.com/econ305.html}}

Most of the methods that you will encounter rely on some variant of this strategy,
which is designed to maximize the ability to estimate the effect
of an average unit being offered the treatment being evaluated.
The focus on identification of the treatment effect, however,
means there are several essential features to this approach
that are not common in other types of statistical and data science work.
First, the econometric models and estimating equations used
do not attempt to create a predictive or comprehensive model
of how the outcome of interest is generated.
Typically, these designs are not interested in predictive accuracy,
and the estimates and predictions that these models produce
will not be as good at predicting outcomes or fitting the data as other models.
Additionally, when control variables or other variables are used in estimation,
there is no guarantee that those parameters are marginal effects.
They can only be interpreted as correlative averages,
unless the experimenter has additional sources of identification for them.
The models you will construct and estimate are intended to do exactly one thing:
to express the intention of your project's research design,
and to accurately estimate the effect of the treatment it is evaluating.
In other words, these models tell the story of the research design
in a way that clarifies the exact comparison being made between control and treatment.

%-----------------------------------------------------------------------------------------------
\subsection{Experimental and quasi-experimental research designs}

Experimental research designs explicitly allow the research team
to change the condition of the populations being studied,\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/Experimental_Methods}}
often in the form of NGO programs, government regulations,
information campaigns, and many more types of interventions.\cite{banerjee2009experimental}
The classic method is the \textbf{randomized control trial (RCT)}.\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/Randomized_Control_Trials}}
  \index{randomized control trials}
In randomized control trials, the control group is randomized --
that is, from an eligible population,
a random subset of units are not given access to the treatment,
so that they may serve as a counterfactual for those who are.
A randomized control group, intuitively, is meant to represent
how things would have turned out for the treated group
if they had not been treated, and it is particularly effective at doing so
as evidenced by its broad credibility in fields ranging from clinical medicine to development.
However, there are many types of treatments that are impractical or unethical
to effectively approach using an experimental strategy,
and therefore many limitations to accessing ``big questions''
through RCT approaches.\sidenote{
  \url{https://www.nber.org/papers/w14690.pdf}}

Randomized designs all share several major statistical concerns.
The first is the fact that it is always possible to select a control group,
by chance, which was not in fact going to be very similar to the treatment group.
This feature is called randomization noise, and all RCTs share the need to understand
how randomization noise may impact the estimates that are obtained.
Second, takeup and implementation fidelity are extremely important,
since programs will by definition have no effect
if they are not in fact accepted by or delivered to
the people who are supposed to recieve them.
Unfortunately, these effects kick in very quickly and are highly nonlinear:
70\% takeup or efficacy doubles the required sample, and 50\% quadruples it.\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/power-calculations-101-dealing-with-incomplete-take-up}}
Such effects are also very hard to correct ex post,
since they require strong assumptions about the randomness or non-randomness of takeup.
Therefore a large amount of field time and descriptive work
must be dedicated to understanding how these effects played out in a given study,
and often overshadow the effort put into the econometric design itself.

\textbf{Quasi-experimental} research designs,\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/Quasi-Experimental_Methods}}
by contrast, are inference methods based on events not controlled by the research team.
Instead, they rely on ``experiments of nature'',
in which natural variation can be argued to approximate
the type of exogenous variation in treatment availability
that a researcher would attempt to create with an experiment.\cite{dinardo2016natural}
Unlike with carefully planned experimental designs,
quasi-experimental designs typically require the extra luck
of having access to data collected at the right times and places
to exploit events that occurred in the past,
or having the ability to collect data in a time and place
dictated by the availability of identification.
Therefore, these methods often use either secondary data,
or use primary data in a cross-sectional retrospective method.

Quasi-experimental designs therefore can access a much broader range of questions,
and with much less effort in terms of executing an intervention.
However, they require in-depth understanding of the precise events
the researcher wishes to address in order to know what data to collect
and how to model the underlying natural experiment.
Additionally, because the population who will have been exposed
to such events is limited by the scale of the event,
quasi-experimental designs are often power-constrained.
There is nothing the research team can do to increase power
by providing treatment to more people or expanding the control group:
instead, power is typically maximized by ensuring
that sampling is carried out effectively
and that attrition from the sampled groups is dealt with effectively.
Sampling noise and survey non-response are therefore analogous
to the randomization noise and implementation failures
that can be observed in RCT designs, and have similar implications for field work.

%-----------------------------------------------------------------------------------------------
%-----------------------------------------------------------------------------------------------
\section{Obtaining treatment effects from specific research designs}


%-----------------------------------------------------------------------------------------------
\subsection{Cross-sectional designs}

\textbf{Cross-sectional} surveys are the simplest possible study design:
a program is implemented, surveys are conducted, and data is analyzed.
When it is an RCT, a randomization process constructs the control group at random
from the population that is eligible to recieve each treatment.
When it is observational, we present other evidence that a similar equivalence holds.
Therefore, by construction, each unit's receipt of the treatment
is unrelated to any of its other characteristics
and the ordinary least squares (OLS) regression
of outcome on treatment, without any control variables,
is an unbiased estimate of the average treatment effect.
Cross-sectional data is simple to handle because
for research teams do not need track anything over time.
A cross-section is simply a representative set of observations
taken at a single point in time.
If this point in time is after a treatment has been fully delivered,
then the outcome values at that point in time
already reflect the effect of the treatment.

What needs to be carefully maintainted in data for cross-sectional RCTs
is the treatment randomization process itself,
as well as detailed field data about differences
in data quality and loss-to-follow up across groups.\cite{athey2017econometrics}
Only these details are needed to construct the appropriate estimator:
clustering of the estimate is required at the level
at which the treatment is assigned to observations,
and controls are required for variables which
were used to stratify the treatment (in the form of strata fixed effects).\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/impactevaluations/how-randomize-using-many-baseline-variables-guest-post-thomas-barrios}}
\textbf{Randomization inference} can be used
to esetimate the underlying variability in the randomization process
(more on this in the next chapter).
\textbf{Balance checks} are typically reported as evidence of an effective randomization,
and are particularly important when the design is quasi-experimental
(since then the randomization process cannot be simulated explicitly).
However, controls for balance variables are usually unnecessary in RCTs,
because it is certain that the true data-generating process
has no correlation between the treatment and the balance factors.\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/should-we-require-balance-t-tests-baseline-observables-randomized-experiments}}

Analysis is typically straightforward with a strong understanding of the randomization.
A typical analysis will include a decription of the sampling and randomization process,
summary statistics for the eligible population,
balance checks for randomization and sample selection,
a primary regression specification (with multiple hypotheses appropriately adjusted),
additional specifications with adjustments for attrition, balance, and other potential contamination,
and randomization-inference analysis or other placebo regression approaches.
There are a number of tools that are available
to help with the complete process of data collection,\sidenote{
  \url{https://toolkit.povertyactionlab.org/resource/coding-resources-randomized-evaluations}}
to analyze balance,\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/iebaltab}}
and to visualize treatment effects.\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/iegraph}}
Tools and methods for analyzing selective attrition are available.\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/dealing-attrition-field-experiments}}

%-----------------------------------------------------------------------------------------------
\subsection{Differences-in-differences}

Where cross-sectional designs draw their estimates of treatment effects
from differences in outcome levels in a single measurement,
\textbf{differences-in-differences}\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/Difference-in-Differences}}
designs (abbreviated as DD, DiD, diff-in-diff, and other variants)
estimate treatment effects from /textit{changes} in outcomes
between two or more rounds of measurement.
  \index{differences-in-differences}
In these designs, three control groups are used –
the baseline level of treatment units,
the baseline level of non-treatment units,
and the endline level of non-treatment units.\sidenote{
  \url{https://www.princeton.edu/~otorres/DID101.pdf}}
The estimated treatment effect is the excess change
of units that recieve the treatment, as they recieve it:
calculating that value is equivalent to taking
the difference in means at endline and subtracting
the difference in means at baseline
(giving the name of a ``difference-in-differences'').\cite{mckenzie2012beyond}
The regression model includes a control variable for treatment assignment,
and a control variable for the measurement round,
but the treatment effect estimate corresponds to
an interaction variable for treatment and round:
the group of observations for which the treatment is active.
This model critically depends on the assumption that,
in the absense of the treatment,
the two groups would have changed performance at the same rate over time,
typically referred to as the \textbf{parallel trends} assumption.\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/often-unspoken-assumptions-behind-difference-difference-estimator-practice}}

There are two main types of data structures for differences-in-differences:
\textbf{repeated cross-sections} and \textbf{panel data}.
In repeated cross-sections, each round contains a random sample
of observations from the treated and untreated groups;
as in cross-sectional designs, both the randomization and sampling processes,
as well as their execution in the field,
are critically important to maintain alongside the survey results.
In panel data structures, we attempt to observe the exact same units
in the repeated rounds, so that we see the same individuals
both before and after they have recieved treatment (or not).\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/what-are-we-estimating-when-we-estimate-difference-differences}}
This allows each unit's baseline outcome to be used
as an additional control for its endline outcome,
a \textbf{fixed effects} design often referred to as an ANCOVA model,
which can provide large increases in power and robustness.\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/another-reason-prefer-ancova-dealing-changes-measurement-between-baseline-and-follow}}
When tracking individuals over rounds for this purpose,
maintaining sampling and tracking records is especially important,
because attrition and loss-to-follow-up will remove that unit's information
from all rounds of observation, not just the one they are unobserved in.
Panel-stype experiments therefore require substantially more effort
in the field work portion.\sidenote{
  \url{https://www.princeton.edu/~otorres/Panel101.pdf}}
Since baseline and endline data collection may be far apart,
it is important to create careful records during the first round
so that follow-ups can be conducted with the same subjects,
and attrition across rounds can be properly taken into account.\sidenote{
  \url{http://blogs.worldbank.org/impactevaluations/dealing-attrition-field-experiments}}

As with cross-sectional designs, this set of study designs is widespread.
Therefore there exist a large number of standardized tools for analysis.
Our \texttt{ietoolkit} package includes the \texttt{ieddtab} command
which produces standardized tables for reporting results.\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/ieddtab}}
For more complicated versions of the model
(and they can get quite complicated quite quickly),
you can use an online dashboard to simulate counterfactual results.\sidenote{
  \url{https://blogs.worldbank.org/impactevaluations/econometrics-sandbox-event-study-designs-co}}
As in cross-sectional designs, these main specifications
will always be accompanied by balance checks (using baseline values),
as well as randomization, selection, and attrition analysis.
In trials of this type, reporting experimental design and execution
using the CONSORT style is common in many disciplines
and will help you to track your data over time.\cite{schulz2010consort}

%-----------------------------------------------------------------------------------------------
\subsection{Regression discontinuity}

\textbf{Regression discontinuity (RD)} designs exploit sharp breaks or limits
in policy designs to separate a group of potentially eligible recipients
into comparable gorups of individuals who do and do not recieve a treatment.\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/Regression_Discontinuity}}
These types of designs differ from cross-sectional and diff-in-diff designs
in that the group eligible to recieve treatment is not defined directly,
but instead created during the process of the treatment implementation.
  \index{regression discontinuity}
In an RD design, there is typically some program or event
which has limited availability dye to practical considerations or poicy choices
and is therefore made available only to individuals who meet a certain threshold requirement.
The intuition of this design is that there is an underlying \textbf{running variable}
which serves as the sole determinant of access to the program,
and a strict cutoff determines the value of this variable at which eligibility stops.\cite{imbens2008regression}
Common examples are test score thresholds, income thresholds, and some types of lotteries.\sidenote{
  \url{http://blogs.worldbank.org/impactevaluations/regression-discontinuity-porn}}
The intuition is that individuals who are just on the recieving side of the threshold
will be very nearly indistinguishable from those on the non-receiving side,
and their post-treatment outcomes are therefore directly comparable.\cite{lee2010regression}
The key assumption here is that the running variable cannot be directly manipulated
by the potential recipients; if the running variable is time there are special considerations.\cite{hausman2018regression}

Regression discontinuity designs are, once implemented,
very similar in analysis to cross-sectional or differences-in-differences designs.
Depending on the data that is available,
the analytical approach will center on the comparison of individuals
who are narrowly on the inclusion side of the discontinuity,
compared against those who are narrowly on the exclusion side.\sidenote{
  \url{https://cattaneo.princeton.edu/books/Cattaneo-Idrobo-Titiunik_2019\_CUP-Vol1.pdf}}
The regression model will be identical to the matching research designs
(ie, contingent whether data has one or more rounds
and whether the same units are known to be observed repeatedly).
The treatment effect will be identified, however, by the addition of a control
for the running variable -- meaning that the treatment effect variable
will only be applicable for observations in a small window around the cutoff.
In the RD model, the functional form of that control and the size of that window
(often referred to as the choice of \textbf{bandwidth} for the design)
are the critical parameters for the result.\cite{calonico2019regression}
Therefore, RD analysis often includes extensive robustness checking
using a variety of both functional forms and bandwidths,
as well as placebo testing for non-realized locations of the cutoff
(conceptually similar to the idea of randomization inference).

In the analytical stage, regression discontinuity designs
often include a large component of visual evidence presentation.\sidenote{
  \url{http://faculty.smu.edu/kyler/courses/7312/presentations/baumer/Baumer\_RD.pdf}}
These presentations help to suggest both the functional form
of the underlying relationship and the type of change observed at the discontinuity,
and help to avoid pitfalls in modelling that are difficult to detect with hypothesis tests.\sidenote{
  \url{http://econ.lse.ac.uk/staff/spischke/ec533/RD.pdf}}
Because these designs are so flexible compared to others,
there is an extensive set of commands that help assess
the efficacy and results from these designs under various assumptions.\sidenote{
  \url{https://sites.google.com/site/rdpackages/}}
These packages support the testing and reporting
of robust plotting and estimation procedures,
tests for manipulation of the running variable,
and tests for power, sample size, and randomization inference approaches
that will complement the main regression approach used for point estimates.

%-----------------------------------------------------------------------------------------------
\subsection{Instrumental variables}

\textbf{Instrumental variables (IV)} designs, unlike the previous approaches,
begins by assuming that the treatment delivered in the study in question is
inextricably linked to the outcomes and therefore not directly identifiable.
Instead, similar to regression discontinuity designs,
it attempts to focus on a subset of the variation in treatment uptake
and assesses that limited window of variation that can be argued
to be unrelated to other factors.\cite{angrist2001instrumental}
To so so, the IV approach selects an \textbf{instrument}
for the treatment status -- an otherwise-unrelated predictor of exposure to treatment
that affects the uptake status of an individual.\sidenote{
  \url{https://dimewiki.worldbank.org/wiki/instrumental_variables}}
Whereas regression discontinuity designs are ``sharp'' --
treatment status is completely determined by which side of a cutoff an individual is on --
IV designs are ``fuzzy'', meaning that they do not completely determine
the treatment status but instead influence the \textit{probability} of treatment.

As in regression discontinuity designs,
the fundamental form of the regression
is similar to either cross-sectional or differences-in-differences designs.
However, instead of controlling for the running variable directly,
the IV approach typically uses the \textbf{two-stage-least-squares (2SLS)} estimator.\sidenote{
  \url{http://www.nuff.ox.ac.uk/teaching/economics/bond/IV\%20Estimation\%20Using\%20Stata.pdf}}
This estimator forms a prediction of the probability that the unit recieves treatment
based on a regression against the instrumental variable.
That prediction will, by assumption, be the portion of the actual treatment
that is due to the instrument and not any other source,
and since the instrument is unrelated to all other factors,
this portion of the treatment can be used to assess its effects.
Unfortunately, these estimators are known
to have very high variances relative other methods,
particularly when the relationship between the intrument and the treatment is small.\cite{young2017consistency}
IV designs furthermore rely on strong but untestable assumptions
about the relationship between the instrument and the outcome.\cite{bound1995problems}
Therefore IV designs face intense scrutiny on the strength and exogeneity of the instrument,
and tests for sensitivity to alternative specifications and samples
are usually required with an instrumental variables analysis.
However, the method has special experimental cases that are significantly easier to assess:
for example, a randomized treatment \textit{assignment} can be used as an instrument
for the eventual uptake of the treatment itself,
especially in cases where uptake is expected to be low,
or in circumstances where the treatment is available
to those who are not specifically assigned to it (``encouragement designs'').

In practice, there are a variety of packages that can be used
to analyse data and report results from instrumental variables designs.
While the built-in command \texttt{ivregress} will often be used
to create the final results, these are not sufficient on their own.
The \textbf{first stage} of the design should be extensively tested,
to demonstrate the strength of the relationship between
the instrument and the treatment variable being instrumented.\cite{stock2005weak}
This can be done using the \texttt{weakiv} and \texttt{weakivtest} commands.\sidenote{
  \url{https://www.carolinpflueger.com/WangPfluegerWeakivtest_20141202.pdf}}
Additionally, tests should be run that identify and exclude individual
observations or clusters that have extreme effects on the estimator,
using customized bootstrap or leave-one-out approaches.
Finally, bounds can be constructed allowing for imperfections
in the exogeneity of the instrument using loosened assumptions,
particularly when the underlying instrument is not directly randomized.\sidenote{
  \url{http://www.damianclarke.net/research/papers/practicalIV-CM.pdf}}


%-----------------------------------------------------------------------------------------------
\subsection{Matching estimators}

\textbf{Matching} estimators rely on the assumption that,
\index{matching}
conditional on some observable characteristics,
untreated units can be compared to treated units,
as if the treatment had been fully randomized.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Matching}}
In other words, they assert that differential takeup
is sufficiently predictable by observed characteristics.
These assertions are somewhat testable,\sidenote{\url{https://dimewiki.worldbank.org/wiki/iematch}}
and there are a large number of ``treatment effect''
packages devoted to standardizing reporting of various tests.\sidenote{\url{http://fmwww.bc.edu/repec/usug2016/drukker_uksug16.pdf}}

However, since most matching models rely on a specific linear model,
such as the typical \textbf{propensity score matching} estimator,
they are open to the criticism of ``specification searching'',
meaning that researchers can try different models of matching
until one, by chance, leads to the final result that was desired.
Newer methods, such as \textbf{coarsened exact matching},\cite{iacus2012causal}
are designed to remove some of the modelling,
such that simple differences between matched observations
are sufficient to estimate treatment effects
given somewhat weaker assumptions on the structure of that effect.
One solution, as with the experimental variant of 2SLS proposed above,
is to incorporate matching models into explicitly experimental designs.

%-----------------------------------------------------------------------------------------------
\subsection{Synthetic controls}

\textbf{Synthetic controls} methods\cite{abadie2015comparative}
\index{synthetic controls}
are designed for a particularly interesting situation:
one where useful controls for an intervention simply do not exist.
Canonical examples are policy changes at state or national levels,
since at that scope there are no other units quite like
the one that was affected by the policy change
(much less sufficient \textit{N} for a regression estimation).\cite{gobillon2016regional}
In this method, \textbf{time series data} is almost always required,
and the control comparison is contructed by creating
a linear combination of other units such that pre-treatment outcomes
for the treated unit are best approximated by that specific combination.
