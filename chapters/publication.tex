%------------------------------------------------

\begin{fullwidth}
Increasingly, research assistants are relied on to manage some or all
of the publication process. This can include
managing the choice of software,
coordinating referencing and bibliography,
tracking changes across various authors and versions,
and preparing final reports or papers for release or submission.
Modern software tools can make a lot of these processes easier.
Unfortunately there is some learning curve,
particularly for lead authors who have been publishing for a long time.
This chapter suggests some tools and processes
that can make writing and publishing in a team significantly easier.
It will provide resources
to judge how best to adapt your team to the tools you agree upon,
since all teams vary in composition and technical experience.

Ideally, your team will spend as little time as possible
fussing with the technical requirements of publication.
It is in nobody's interest for a skilled and busy research assistant
to spend days re-numbering references (and it can take days)
if a small amount of up-front effort could automate the task.
However, experienced academics will likely have a workflow
with which they are already comfortable,
and since they have worked with many others in the past,
that workflow is likely to be the least-common-denominator:
Microsoft Word with tracked changes.
This chapter will show you how you can avoid at least some
of the pain of Microsoft Word,
while still providing materials in the format
that co-authors prefer and journals request.
\end{fullwidth}

%------------------------------------------------

\section{Collaborating on technical writing}

It is increasingly rare that a single author will prepare an entire manuscript alone.
More often than not, documents will pass back and forth between several writers
before they are prepared for publication,
so it is essential to use technology and workflows that avoid conflicts.
Just as with the preparation of analytical outputs,
this means adopting tools practices that enable tasks
such as version control and simultaneous contribution.
Furthermore, it means preparing documents that are \textbf{dynamic} --
meaning that updates to the analytical outputs that constitute them
can be updated in the final output with a single process,
rather than copy-and-pasted or otherwise handled individually.
Thinking of the writing process in this way
is intended to improve organization and reduce error,
such that there is no risk of materials being compiled
with out-of-date results, or of completed work being lost or redundant.

\subsection{Dynamic documents}

Dynamic documents are a broad class of tools that enable such a workflow.
The term ``dynamic'' can refer to any document-creation technology
that allows the creation of explicit references to raw output files.
This means that, whenever outputs are updated,
the next iteration of the document will automatically include
all changes made to all outputs without any additional intervention from the writer.
This means that updates will never be accidentally excluded,
and it further means that updating results will never become more difficult
as the number of inputs grows,
because they are all managed by a single integrated process.

You will note that this is not possible in tools like Microsoft Office.
In Word, for example, you have to copy and paste each object individually
whenever there are materials that have to be updated.
This means that both the features above are not available:
fully updating the document becomes more and more time-consuming
as the number of inputs increases,
and it therefore becomes more and more likely
that a mistake will be made or something will be missed.
Furthermore, it is very hard to simultaneously edit or track changes
in a Microsoft Word document.
It is usually the case that a file needs to be passed back and forth
and the order of contributions strictly controlled
so that time-consuming resolutions of differences can be avoided.
Therefore this is a broadly unsuitable way to prepare technical documents.

There are a number of tools that can be used for dynamic documents.
They fall into two broad groups --
the first which compiles a document as part of code execution,
and the second which operates a separate document compiler.
In the first group are tools such as R's RMarkdown and Stata's \texttt{dyndoc}.
These tools ``knit'' or ``weave'' text and code together,
and are programmed to insert code outputs in pre-specified locations.
Documents called ``notebooks'' (such as Jupyter) work similarly,
as they also use the underlying analytical software to create the document.
These types of dynamic documents are usually appropriate for short or informal materials
because they tend to offer limited editability outside the base software
and often have limited abilities to incorporate precision formatting.

On the other hand, some dynamic document tools do not require
operation of any underlying software, but simply require
that the writer have access to the updated outputs.
One very simple one is Dropbox Paper, a free online writing tool
that allows linkages to files in Dropbox,
which are then automatically updated anytime the file is replaced.
Like the first class of tools, Dropbox Paper has very limited formatting options,
but it is appropriate for work with collaborators who are not using statistical software.
However, the most widely utilized software
for dynamically managing both text and results is \LaTeX\.\sidenote{
  \url{https://www.maths.tcd.ie/~dwilkins/LaTeXPrimer/GSWLaTeX.pdf}}
  \index{\LaTeX}
(\LaTeX\ also operates behind-the-scenes in many other tools.)
While this tool has a significant learning curve,
its enormous flexibility in terms of operation, collaboration,
and output formatting and styling
makes it the primary choice for most large technical outputs today.

\subsection{Technical writing with \LaTeX}

\LaTeX\ is billed as a ``document preparation system''.
What this means is worth unpacking.
In \LaTeX\, instead of writing in a ``what-you-see-is-what-you-get'' mode
as you do in Word or the equivalent,
you write plain text interlaced with specific instructions for formatting
(similar in concept to HTML).
The \LaTeX\ system includes commands for simple markup
like font styles, paragraph formatting, section headers and the like.
But it also includes special controls for including tables and figures,
footnotes and endnotes, complex mathematics, and automated bibliography preparation.
It also allows publishers to apply global styles and templates
to already-written material, allowing them to reformat entire documents in house styles
with only a few keystrokes.
In sum, \LaTeX\ enables automatically-organized documents,
manages tables and figures dynamically,
and (because it is written in plain text) can be version-controlled using Git.
This is why it has become the dominant ``document preparation system'' in technical writing.

Unfortunately, \LaTeX\ can be a challenge to set up and use at first,
particularly if you are new to working with plain text code and file management.
\LaTeX\ requires that all formatting be done in its special code language,
and it is not particularly informative when you do something wrong.
This can be off-putting very quickly for people
who simply want to get to writing, like senior researchers.
While integrated editing and compiling tools like TeXStudio\sidenote{
  \url{https://www.texstudio.org}}
and \texttt{atom-latex}\sidenote{
  \url{https://atom.io/packages/atom-latex}}
offer the most flexibility to work with \LaTeX\ on your computer,
such as advanced integration with Git,
the entire team needs to be comfortable
with \LaTeX\ before adopting one of these tools.
They can require a lot of troubleshooting at a basic level at first,
and non-technical staff may not be willing or able to acquire the required knowledge.
Therefore, to take advantage of the features of \LaTeX,
while making it easy and accessible to the entire writing team,
we need to abstract away from the technical details where possible.

One of the most important tools available in \LaTeX\ is the BibTeX bibliography manager.\sidenote{
  \url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.365.3194&rep=rep1&type=pdf}}
BibTeX keeps all the references you might use in an auxiliary file,
then references them as plain text in the document using a \LaTeX\ command.
The same principles that apply to figures and tables are therefore applied here:
You can make changes to the references in one place (the \texttt{.bib} file),
and then everywhere they are used they are updated correctly with one process.
Specifically, \LaTeX\ inserts references in text using the \texttt{\textbackslash cite\{\}} command.
Once this is written, \LaTeX\ automatically pulls all the citations into text
and creates a complete bibliography based on the citations you use when you compile the document.
The system allows you to specify exactly how references should be displayed in text
(such as superscripts, inline references, etc.)
as well as how the bibliography should be styled and in what order
(such as Chicago, MLA, Harvard, or other common styles).
To obtain the references for the \texttt{.bib} file,
you can copy the specification directly from Google Scholar
by clicking ``BibTeX'' at the bottom of the Cite window.
When pasted into the \texttt{.bib} file they look like the following:

\codeexample{sample.bib}{./code/sample.bib}

\noindent BibTeX citations are then used as follows:

\codeexample{citation.tex}{./code/citation.tex}

With these tools, you can ensure that references are handled
in a format you can manage and control.\cite{flom2005latex}
Finally, \LaTeX\ has one more useful trick:
using \textbf{\texttt{pandoc}},\sidenote{
  \url{http://pandoc.org/}}
you can translate the raw document into Word
(or a number of other formats)
by running the following code from the command line:

\codeexample{pandoc.sh}{./code/pandoc.sh}

\noindent The last portion after \texttt{--csl=} specifies the bibliography style.
You can download a CSL (Citation Styles Library) file\sidenote{
  \url{https://github.com/citation-style-language/styles}}
for nearly any journal and have it applied automatically in this process.
Therefore, even in the case where you are requested to provide
\texttt{.docx} versions of materials to others, or tracked-changes versions,
you can create them effortlessly,
and use external tools like Word's compare feature
to generate integrated tracked versions when needed.

\subsection{Getting started with \LaTeX\ via Overleaf}

The easiest way for someone new to \LaTeX\ to be able to ``just write''
is often the web-based Overleaf suite.\sidenote{
  \url{https://www.overleaf.com}}
Overleaf offers a text editor that behaves pretty similarly to familiar tools like Word,
and it is free-to-use for a broad variety of basic applications.
It allows simultaneous online editing and invitations similarly to Google Docs,
handles most of the basic under-the-hood technical requirements.
Overleaf also offers a convenient selection of templates
so it is easy to start up a project and see results right away.
On the downside, there is a small amount of up-front learning required,
continous access to the Internet is necessary,
and updating figures and tables requires a bulk file upload that is tough to automate.

The purpose of this setup, just like with other synced folders,
is to avoid there ever being more than one master copy of the document.
This means that people can edit simultaneously without fear of conflicts,
and it is never necessary to manually resolve differences in the document.

One of the most common issues you will face using Overleaf will be special characters
which, because of code functions, need to be handled differently than in Word.
Most critically, the ampersand (\texttt{\&}), percent (\texttt{\%}), and underscore (\texttt{\_})
need to be ``escaped'' (interpreted as text and not code) in order to render.
This is done by by writing a backslash (\texttt{\textbackslash}) before them,
such as writing \texttt{40\textbackslash\%} for the percent sign to appear in text.
Despite this, we believe that with minimal learning and workflow adjustments,
Overleaf is often the easiest way to allow coauthors to write and edit in \LaTeX\,
so long as you make sure you are available to troubleshoot minor issues like these.









%------------------------------------------------

\section{Preparing a complete replication package}

\section{Publishing data for replication}

\section{Publishing code for replication}

Data and code should always be released with any publication.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Publishing_Data}}
\index{data publication}
Many journals and funders have strict open data policies,
and providing these materials to other researchers
allows them to evaluate the credibility of your work
as well as to re-use your materials for further research.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Exporting_Analysis}}
If you have followed the steps in this book carefully,
you will find that this is a very easy requirement to fulfill.\sidenote{
\url{https://www.bitss.org/2016/05/23/out-of-the-file-drawer-tips-on-prepping-data-for-publication/}}
You will already have a publishable (either de-identified or constructed)
version of your research dataset.
You will already have your analysis code well-ordered,
and you won't have any junk lying around for cleanup.
You will have written your code so that others can read it,
and you will have documentation for all your work,
as well as a well-structured directory containing the code and data.

If you are at this stage,
all you need to do is find a place to publish your work!
GitHub provides one of the easiest solutions here,
since it is completely free for static, public projects
and it is straightforward to simply upload a fixed directory
and obtain a permanent URL for it.
The Open Science Framework also provides a good resource,
as does ResearchGate (which can also assign a permanent
digital object identifier link for your work).
Any of these locations is acceptable --
the main requirement is that the system can handle
the structured directory that you are submitting,
and that it can provide a stable, structured URL for your project.

You should release a structured directory that allows a user
to immediately run your code after changing the project directory.
The folders should include:
all necessary de-identified data for the analysis
(including only the data needed for analysis);
the data documentation for the analysis code
(describing the source and construction of variables);
the ready-to-run code necessary for the analysis; and
the raw outputs you have used for the paper.
Using \texttt{iefolder} from our \texttt{ietoolkit} can help standardize this in Stata.
In either the \texttt{/dofiles/} folder or in the root directory,
include a master script (\texttt{.do} or \texttt{.r} for example).
The master script should allow the reviewer to change
one line of code setting the directory path.
Then, running the master script should run the entire project
and re-create all the raw outputs exactly as supplied.
Check that all your code will run completely on a new computer.
This means installing any required user-written commands in the master script
(for example, in Stata using \texttt{ssc install} or \texttt{net install}
and in R include code for installing packages,
including installing the appropriate version of the package if necessary).
Make sure settings like \texttt{version}, \texttt{matsize}, and \texttt{varabbrev} are set.\sidenote{In Stata, \texttt{ietoolkit}'s \texttt{ieboilstart} command will do this for you.}
All outputs should clearly correspond by name to an exhibit in the paper, and vice versa.

Finally, you may also want to release an author's copy or preprint.
Check with your publisher before doing so;
not all journals will accept material that has been released.
Therefore you may need to wait until acceptance is confirmed.
This can be done on a number of pre-print websites,
many of which are topically-specific.
You can also use GitHub and link the file directly
on your personal website or whatever medium you are
sharing the preprint through.
Do not use Dropbox or Google Drive for this purpose:
many organizations do not allow access to these tools,
and that includes blocking staff from accessing your material.
