%------------------------------------------------

\begin{fullwidth}
Increasingly, research assistants are relied on to manage some or all
of the publication process. This can include
managing the choice of software,
coordinating referencing and bibliography,
tracking changes across various authors and versions,
and preparing final reports or papers for release or submission.
Modern software tools can make a lot of these processes easier.
Unfortunately there is some learning curve,
particularly for lead authors who have been publishing for a long time.
This chapter suggests some tools and processes
that can make writing and publishing in a team significantly easier.
It will provide resources
to judge how best to adapt your team to the tools you agree upon,
since all teams vary in composition and technical experience.

Ideally, your team will spend as little time as possible
fussing with the technical requirements of publication.
It is in nobody's interest for a skilled and busy research assistant
to spend days re-numbering references (and it can take days)
if a small amount of up-front effort could automate the task.
However, experienced academics will likely have a workflow
with which they are already comfortable,
and since they have worked with many others in the past,
that workflow is likely to be the least-common-denominator:
Microsoft Word with tracked changes.
This chapter will show you how you can avoid at least some
of the pain of Microsoft Word,
while still providing materials in the format
that co-authors prefer and journals request.
\end{fullwidth}

%------------------------------------------------

\section{Collaborating on technical writing}

It is increasingly rare that a single author will prepare an entire manuscript alone.
More often than not, documents will pass back and forth between several writers
before they are prepared for publication,
so it is essential to use technology and workflows that avoid conflicts.
Just as with the preparation of analytical outputs,
this means adopting tools practices that enable tasks
such as version control and simultaneous contribution.
Furthermore, it means preparing documents that are \textbf{dynamic} --
meaning that updates to the analytical outputs that constitute them
can be updated in the final output with a single process,
rather than copy-and-pasted or otherwise handled individually.
Thinking of the writing process in this way
is intended to improve organization and reduce error,
such that there is no risk of materials being compiled
with out-of-date results, or of completed work being lost or redundant.

\subsection{Dynamic documents}

Dynamic documents are a broad class of tools that enable such a workflow.
The term ``dynamic'' can refer to any document-creation technology
that allows the creation of explicit references to raw output files.
This means that, whenever outputs are updated,
the next iteration of the document will automatically include
all changes made to all outputs without any additional intervention from the writer.
This means that updates will never be accidentally excluded,
and it further means that updating results will never become more difficult
as the number of inputs grows,
because they are all managed by a single integrated process.

You will note that this is not possible in tools like Microsoft Office.
In Word, for example, you have to copy and paste each object individually
whenever there are materials that have to be updated.
This means that both the features above are not available:
fully updating the document becomes more and more time-consuming
as the number of inputs increases,
and it therefore becomes more and more likely
that a mistake will be made or something will be missed.
Furthermore, it is very hard to simultaneously edit or track changes
in a Microsoft Word document.
It is usually the case that a file needs to be passed back and forth
and the order of contributions strictly controlled
so that time-consuming resolutions of differences can be avoided.
Therefore this is a broadly unsuitable way to prepare technical documents.

There are a number of tools that can be used for dynamic documents.
They fall into two broad groups --
the first which compiles a document as part of code execution,
and the second which operates a separate document compiler.
In the first group are tools such as R's RMarkdown and Stata's \texttt{dyndoc}.
These tools ``knit'' or ``weave'' text and code together,
and are programmed to insert code outputs in pre-specified locations.
Documents called ``notebooks'' (such as Jupyter) work similarly,
as they also use the underlying analytical software to create the document.
These types of dynamic documents are usually appropriate for short or informal materials
because they tend to offer limited editability outside the base software
and often have limited abilities to incorporate precision formatting.

On the other hand, some dynamic document tools do not require
operation of any underlying software, but simply require
that the writer have access to the updated outputs.
One very simple one is Dropbox Paper, a free online writing tool
that allows linkages to files in Dropbox,
which are then automatically updated anytime the file is replaced.
Like the first class of tools, Dropbox Paper has very limited formatting options,
but it is appropriate for work with collaborators who are not using statistical software.
However, the most widely utilized software
for dynamically managing both text and results is \LaTeX.\sidenote{
  \url{https://www.maths.tcd.ie/~dwilkins/LaTeXPrimer/GSWLaTeX.pdf}}
  \index{\LaTeX}
(\LaTeX also operates behind-the-scenes in many other tools.)
While this tool has a significant learning curve,
its enormous flexibility in terms of operation, collaboration,
and output formatting and styling
makes it the primary choice for most large technical outputs today.

\subsection{Technical writing with \LaTeX}

The gold standard for academic writing is \LaTeX.
\LaTeX\ allows automatically-organized sections like titles and bibliographies,
imports tables and figures in a dynamic fashion,
and can be version controlled using Git.
Unfortunately, \LaTeX\ can be a challenge to set up and use at first,
particularly for people who are unfamiliar with plaintext, code, or file management.
\LaTeX\ requires that all formatting be done in its special code language,
and it is not particularly informative when you do something wrong.
This can be off-putting very quickly for people
who simply want to get to writing, like lead authors.
Therefore, if we want to take advantage of the features of \LaTeX,
without getting stuck in the weeds of it,
we will need to adopt a few tools and tricks to make it effective.

The first is choice of software. The easiest way
for someone new to \LaTeX\ to be able to ``just write''
is often the web-based Overleaf suite.\sidenote{\url{https://www.overleaf.com}}
Overleaf offers a \textbf{rich text editor}
that behaves pretty similarly to familiar tools like Word.
With minimal workflow adjustments, you can
to show coauthors how to write and edit in Overleaf,
so long as you make sure you are always available to troubleshoot
\LaTeX\ crashes and errors. It also offers a convenient selection of templates
so it is easy to start up a project
and replicate a lot of the underlying setup code.
One  of the most common issues you will face while using Overleaf will be special characters, namely
\texttt{\&}, \texttt{\%}, and \texttt{\_},
which need to be \textbf{escaped} (instructed to interpret literally)
by writing a backslash (\texttt{\textbackslash}) before them,
such as  \texttt{40\textbackslash\%} for the percent sign to function.
Another issue is that you need to upload input files
(such as figures and tables) manually.
This can create conflicts when these inputs are still being updated --
namely, the main document not having the latest results.
One solution is to move to Overleaf only once there will not be substantive changes to results.

Other popular desktop-based tools for writing \LaTeX are TeXstudio\sidenote{\url{https://www.texstudio.org}} and atom-latex\sidenote{\url{https://atom.io/packages/atom-latex}}.
They allow more advanced integration with Git,
among other advantages, but the entire team needs to be comfortable
with \LaTeX\ before adopting one of these tools.

One of the important tools available in \LaTeX\ is the \textbf{BibTeX bibliography manager}.\sidenote{\url{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.365.3194&rep=rep1&type=pdf}}
This tool stores unformatted references
in an accompanying \texttt{.bib} file,
and \LaTeX\ then inserts them in text
using the \texttt{\textbackslash cite\{\}} command.
With this structure, \LaTeX\ automatically pulls
all the citations into text. \LaTeX\ allows you to specify
how they should be displayed in text
(ie, as superscripts, inline references, etc.)
and how the bibliography should be styled and in what order.
A reference in the \texttt{.bib} file
can be copied directly from Google Scholar
by clicking "BibTeX" at the bottom of the Cite window.
When pasted into the \texttt{.bib} file they look like the following:

\codeexample{sample.bib}{./code/sample.bib}

\noindent BibTeX citations are then used as follows:

\codeexample{citation.tex}{./code/citation.tex}

With these tools, you can ensure that co-authors are writing
in a format you can manage and control.\cite{flom2005latex}
The purpose of this setup, just like with other synced folders,
is to avoid there ever being more than one master copy of the document.
This means that people can edit simultaneously without fear of conflicts,
and it is never necessary to manually resolve differences in the document.
Finally, \LaTeX\ has one more useful trick:
if you download a journal styler from the \textbf{Citation Styles Library}\sidenote{
\url{https://github.com/citation-style-language/styles}}
and use \textbf{\texttt{pandoc}},\sidenote{\url{http://pandoc.org/}}
you can translate the raw document into Word by running the following code from the command line:

\codeexample{pandoc.sh}{./code/pandoc.sh}

Therefore, even in the case where you are requested to provide
\texttt{.docx} versions of materials to others, or tracked-changes versions,
you can create them effortlessly,
and use Word's compare feature to generate a single integrated tracked version.

%------------------------------------------------

\section{Preparing a complete replication package}

\section{Publishing data for replication}

\section{Publishing code for replication}

Data and code should always be released with any publication.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Publishing_Data}}
\index{data publication}
Many journals and funders have strict open data policies,
and providing these materials to other researchers
allows them to evaluate the credibility of your work
as well as to re-use your materials for further research.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Exporting_Analysis}}
If you have followed the steps in this book carefully,
you will find that this is a very easy requirement to fulfill.\sidenote{
\url{https://www.bitss.org/2016/05/23/out-of-the-file-drawer-tips-on-prepping-data-for-publication/}}
You will already have a publishable (either de-identified or constructed)
version of your research dataset.
You will already have your analysis code well-ordered,
and you won't have any junk lying around for cleanup.
You will have written your code so that others can read it,
and you will have documentation for all your work,
as well as a well-structured directory containing the code and data.

If you are at this stage,
all you need to do is find a place to publish your work!
GitHub provides one of the easiest solutions here,
since it is completely free for static, public projects
and it is straightforward to simply upload a fixed directory
and obtain a permanent URL for it.
The Open Science Framework also provides a good resource,
as does ResearchGate (which can also assign a permanent
digital object identifier link for your work).
Any of these locations is acceptable --
the main requirement is that the system can handle
the structured directory that you are submitting,
and that it can provide a stable, structured URL for your project.

You should release a structured directory that allows a user
to immediately run your code after changing the project directory.
The folders should include:
all necessary de-identified data for the analysis
(including only the data needed for analysis);
the data documentation for the analysis code
(describing the source and construction of variables);
the ready-to-run code necessary for the analysis; and
the raw outputs you have used for the paper.
Using \texttt{iefolder} from our \texttt{ietoolkit} can help standardize this in Stata.
In either the \texttt{/dofiles/} folder or in the root directory,
include a master script (\texttt{.do} or \texttt{.r} for example).
The master script should allow the reviewer to change
one line of code setting the directory path.
Then, running the master script should run the entire project
and re-create all the raw outputs exactly as supplied.
Check that all your code will run completely on a new computer.
This means installing any required user-written commands in the master script
(for example, in Stata using \texttt{ssc install} or \texttt{net install}
and in R include code for installing packages,
including installing the appropriate version of the package if necessary).
Make sure settings like \texttt{version}, \texttt{matsize}, and \texttt{varabbrev} are set.\sidenote{In Stata, \texttt{ietoolkit}'s \texttt{ieboilstart} command will do this for you.}
All outputs should clearly correspond by name to an exhibit in the paper, and vice versa.

Finally, you may also want to release an author's copy or preprint.
Check with your publisher before doing so;
not all journals will accept material that has been released.
Therefore you may need to wait until acceptance is confirmed.
This can be done on a number of pre-print websites,
many of which are topically-specific.
You can also use GitHub and link the file directly
on your personal website or whatever medium you are
sharing the preprint through.
Do not use Dropbox or Google Drive for this purpose:
many organizations do not allow access to these tools,
and that includes blocking staff from accessing your material.
