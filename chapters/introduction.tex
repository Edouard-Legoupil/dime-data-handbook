\begin{fullwidth}
Welcome to Data for Development Impact.
This book is intended to teach you how to handle data effectively, efficiently, and ethically 
at all stages of the research process: design, data acquisition, and analysis.
This book is not sector-specific. 
It will not teach you econometrics, or how to design an impact evaluation. 
It will teach you how to think about all aspects of your research from a data perspective: 
how to structure every stage of your research to maximize data quality 
and institute transparent and reproducible workflows. 
The central premise of this book is that data work is a ``social process'',
in which many people need to have the same idea about what is to be done, and when and where and by whom,
so that they can collaborate effectively on large, long-term research projects.

An [empirical revolution]{\sidenote\url{https://www.bloomberg.com/opinion/articles/2018-08-02/how-economics-went-from-philosophy-to-science}}
has changed the face of research economics rapidly over the last decade. 
Economics graduate students of the 2000s expected to work with primarily "clean" data from secondhand sources. 
Today, especially in the development subfield, working with raw data- 
whether collected through surveys or acquired through 'big' data sources like sensors, satellites, or call data records- 
is a key skill for researchers and their staff. 
However, most graduates have little or no experience working with raw data when they are recruited as research assistants. 
Therefore they tend to have a large "skills gap" on the practical tasks of development economics research. 
Yet there are few guides to the conventions, standards, and best practices that are fast becoming a necessity for impact evaluation projects.
This book aims to fill that gap, providing a practical resource complete with code snippets and references to concrete resources that allow the reader to immediately put recommended processes into practice.

\end{fullwidth}

%------------------------------------------------

\section{Doing credible research at scale}
Development economics is increasingly dominated by empirical research.\cite{angrist2017economic}
The scope and scale of empirical research projects has expanded rapidly in recent years:
more people are working on the same data over longer timeframes.
As the ambition of development researchers grows, so too has the complexity of the data
on which they rely to make policy-relevant research conclusions from \textbf{field experiments}.\sidenote{
\textbf{Field experiment:} experimental intervention in the real world, rather than in a laboratory.}
Unfortunately, this seems to have happened (so far) without the creation of
standards for practitioners to collaborate efficiently or structure data work for maximal reproducibility.
This book contributes by providing practical guidance on how to handle data efficiently, transparently and collaboratively.

The team responsible for this book is known as \textbf{DIME Analytics}.\sidenote{
\url{http://www.worldbank.org/en/research/dime/data-and-analytics}}
The DIME Analytics team works within the \textbf{Development Impact Evaluation  (DIME)} Department \sidenote{
\url{http://www.worldbank.org/en/research/dime}}
at the World Bank's \textbf{Development Economics (DEC) Vice Presidency}.\sidenote{
\url{https://www.worldbank.org/en/about/unit/unit-dec}}
DIME generates high-quality and operationally relevant data and research 
to transform development policy, help reduce extreme poverty, and secure shared prosperity. 
It develops customized data and evidence ecosystems to produce actionable information 
and recommend specific policy pathways to maximize impact.
DIME conducts research in 60 countries with 200 agencies, leveraging a 
US\$180 million research budget to shape the design and implementation of 
US\$18 billion in development finance. 
DIME also provides advisory services to 30 multilateral and bilateral development agencies. 
Finally, DIME invests in public goods to improve the quality and reproducibility of development research around the world. 

DIME Analytics was created take advantage of the concentration and scale of research at DIME to develop and test solutions, 
to ensure high quality of data collection and research across the DIME portfolio, 
and to make public training and tools available to the larger community of development researchers.
Data for Development Impact compiles the ideas, best practices and software tools Analytics 
has developed while supporting DIME's global impact evaluation portfolio. 
The \textbf{DIME Wiki} is one of our flagship products, a free online collection of our resources and best practices.\sidenote{
\url{http://dimewiki.worldbank.org/}}
This book complements the DIME Wiki by providing a structure narrative of the data workflow for a typical research project. 
We will not give a lot of highly specific details in this text,
but we will point you to where they can be found.\sidenote{Like this: 
\url{https://dimewiki.worldbank.org/wiki/Primary_Data_Collection}}
Each chapter focuses on one task, providing a primarily narrative account of:
what you will be doing; where in the workflow this task falls;
when it should be done; and how to implement it according to best practices.

We will use broad terminology throughout this book
to refer to different team members:
\textbf{principal investigators (PIs)} who are responsible for
the overall success of the project;
\textbf{field coordinators (FCs)} who are responsible for
the operation of the project on the ground;
and \textbf{research assistants (RAs)} who are responsible for
handling technical capacity and analytical tasks.

\section{Writing reproducible code in a collaborative environment}

Research reproduciblity and data quality follow naturally from
good code and standardized practices.
Process standardization means that there is
little ambiguity about how something ought to be done,
and therefore the tools that are used to do it are set in advance.
Good code is easier to read and replicate, making it easier to spot mistakes.
The resulting data contains substantially less noise
that is due to sampling, randomization, and cleaning errors. 
And all data work can be easily reviewed before it's published and replicated afterwards.

A good do-file consists of code that has two elements:
- it is correct (doesn't produce any errors along the way)
- it is useful and comprehensible to someone who hasn't seen it before (such that the person who wrote this code isn't lost if they see it three weeks later)
Most research assistants that join our unit have only been trained in how to code correctly.
While correct results are extremely important, we usually tell our new research assistants that
\textit{when your code runs on your computer and you get the correct results then you are only half-done writing \underline{good} code.}

Just as data collection and management processes have become more social and collaborative,
code processes have as well.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Stata_Coding_Practices}} This means other people need to be able to read your code.
Not only are things like documentation and commenting important,
but code should be readable in the sense that others can:
(1) quickly understand what a portion of code is supposed to be doing;
(2) evaluate whether or not it does that thing correctly; and
(3) modify it efficiently either to test alternative hypotheses
or to adapt into their own work.\sidenote{\url{https://kbroman.org/Tools4RR/assets/lectures/07_clearcode.pdf}}

To accomplish that, you should think of code in terms of three major elements:
\textbf{structure}, \textbf{syntax}, and \textbf{style}.
We always tell people to ``code as if a stranger would read it'',
from tomorrow, that stranger will be you.
The \textbf{structure} is the environment your code lives in:
good structure means that it is easy to find individual pieces of code that correspond to tasks.
Good structure also means that functional blocks are sufficiently independent from each other
that they can be shuffled around, repurposed, and even deleted without damaging other portions.
The \textbf{syntax} is the literal language of your code.
Good syntax means that your code is readable
in terms of how its mechanics implement ideas --
it should not require arcane reverse-engineering
to figure out what a code chunk is trying to do.
\textbf{Style}, finally, is the way that the non-functional elements of your code convey its purpose.
Elements like spacing, indentation, and naming (or lack thereof) can make your code much more 
(or much less) accessible to someone who is reading it for the first time and needs to understand it quickly and correctly.

For some implementation portions where precise code is particularly important,
we will provide minimal code examples either in the book or on the DIME Wiki.
In the book, they will be presented like the following:

\codeexample{code.do}{./code/code.do}

We have tried really hard to make sure that all the Stata code runs,
and that each block is well-formatted and uses built-in functions.
We will also point to user-written functions when they provide important tools.
In particular, we have written two suites of Stata commands,
\texttt{ietoolkit}\sidenote{\url{https://dimewiki.worldbank.org/wiki/ietoolkit}} and \texttt{iefieldkit},\sidenote{\url{https://dimewiki.worldbank.org/wiki/iefieldkit}}
that standardize some of our core data collection workflows.
Providing some standardization to Stata code style is also a goal of this team,
since groups are collaborating on code in Stata more than ever before.
We will not explain Stata commands unless the behavior we are exploiting
is outside the usual expectation of its functionality;
we will comment the code generously (as you should),
but you should reference Stata help-files \texttt{h [command]}
whenever you do not understand the functionality that is being used.
We hope that these snippets will provide a foundation for your code style.
Alongside the collaborative view of data that we outlined above,
good code practices are a core part of the new data science of development research.
Code today is no longer a means to an end (such as a paper),
but it is part of the output itself: it is a means for communicating how something was done,
in a world where the credibility and transparency of data cleaning and analysis is increasingly important.

While adopting the workflows and mindsets described in this book
requires an up-front cost,
it should start to save yourself and others a lot of time and hassle very quickly.
In part this is because you will learn how to do the essential things directly;
in part this is because you will find tools for the more advanced things;
and in part this is because you will have the mindset to doing everything else in a high-quality way.
We hope you will find this book helpful for accomplishing all of the above,
and that you will find that mastery of data helps you make an impact!

\textbf{-- The DIME Analytics Team}

\mainmatter
