\begin{fullwidth}
Welcome to Data for Development Impact.
This book is intended to teach you how to handle data effectively, efficiently, and ethically 
at all stages of the research process: design, data acquisition, and analysis.
This book is not sector-specific. 
It will not teach you econometrics, or how to design an impact evaluation. 
It will teach you how to think about all aspects of your research from a data perspective: 
how to structure every stage of your research to maximize data quality 
and institute transparent and reproducible workflows. 
The central premise of this book is that data work is a ``social process'',
in which many people need to have the same idea about what is to be done, and when and where and by whom,
so that they can collaborate effectively on large, long-term research projects.

An [empirical revolution]{\sidenote\url{https://www.bloomberg.com/opinion/articles/2018-08-02/how-economics-went-from-philosophy-to-science}}
has changed the face of research economics rapidly over the last decade. 
Economics graduate students of the 2000s expected to work with primarily "clean" data from secondhand sources. 
Today, especially in the development subfield, working with raw data- 
whether collected through surveys or acquired through 'big' data sources like sensors, satellites, or call data records- 
is a key skill for researchers and their staff. 
However, most graduates have little or no experience working with raw data when they are recruited as research assistants. 
Therefore they tend to have a large "skills gap" on the practical tasks of development economics research. 
Yet there are few guides to the conventions, standards, and best practices that are fast becoming a necessity for impact evaluation projects.
This book aims to fill that gap, providing a practical resource complete with code snippets and references to concrete resources that allow the reader to immediately put recommended processes into practice.

\end{fullwidth}

%------------------------------------------------

\section{Doing credible research at scale}
Development economics is increasingly dominated by empirical research.\cite{angrist2017economic}
The scope and scale of empirical research projects has expanded rapidly in recent years:
more people are working on the same data over longer timeframes.
As the ambition of development researchers grows, so too has the complexity of the data
on which they rely to make policy-relevant research conclusions from \textbf{field experiments}.\sidenote{
\textbf{Field experiment:} experimental intervention in the real world, rather than in a laboratory.}
Unfortunately, this seems to have happened (so far) without the creation of
standards for practitioners to collaborate efficiently or structure data work for maximal reproducibility.
This book contributes by providing practical guidance on how to handle data efficiently, transparently and collaboratively.

The team responsible for this book is known as \textbf{DIME Analytics}.\sidenote{
\url{http://www.worldbank.org/en/research/dime/data-and-analytics}}
The DIME Analytics team works within the \textbf{Development Impact Evaluation  (DIME)} Department \sidenote{
\url{http://www.worldbank.org/en/research/dime}}
at the World Bank's \textbf{Development Economics (DEC) Vice Presidency}.\sidenote{
\url{https://www.worldbank.org/en/about/unit/unit-dec}}
DIME generates high-quality and operationally relevant data and research 
to transform development policy, help reduce extreme poverty, and secure shared prosperity. 
It develops customized data and evidence ecosystems to produce actionable information 
and recommend specific policy pathways to maximize impact.
DIME conducts research in 60 countries with 200 agencies, leveraging a 
US\$180 million research budget to shape the design and implementation of 
US\$18 billion in development finance. 
DIME also provides advisory services to 30 multilateral and bilateral development agencies. 
Finally, DIME invests in public goods to improve the quality and reproducibility of development research around the world. 

DIME Analytics was created take advantage of the concentration and scale of research at DIME to develop and test solutions, 
to ensure high quality of data collection and research across the DIME portfolio, 
and to make public training and tools available to the larger community of development researchers.
Data for Development Impact compiles the ideas, best practices and software tools Analytics 
has developed while supporting DIME's global impact evaluation portfolio. 
The \textbf{DIME Wiki} is one of our flagship products, a free online collection of our resources and best practices.\sidenote{
\url{http://dimewiki.worldbank.org/}}
This book complements the DIME Wiki by providing a structure narrative of the data workflow for a typical research project. 
We will not give a lot of highly specific details in this text,
but we will point you to where they can be found.\sidenote{Like this: 
\url{https://dimewiki.worldbank.org/wiki/Primary_Data_Collection}}
Each chapter focuses on one task, providing a primarily narrative account of:
what you will be doing; where in the workflow this task falls;
when it should be done; and how to implement it according to best practices.

We will use broad terminology throughout this book
to refer to different team members:
\textbf{principal investigators (PIs)} who are responsible for
the overall success of the project;
\textbf{field coordinators (FCs)} who are responsible for
the operation of the project on the ground;
and \textbf{research assistants (RAs)} who are responsible for
handling raw data processing and analytical tasks.

\section{Writing reproducible code in a collaborative environment}

Research reproduciblity and data quality follow naturally from
good code and standardized processes.
Good code practices are a core part of the new data science of development research.
Code today is no longer a means to an end (such as a research paper),
rather it is part of the output itself: a means for communicating how something was done,
in a world where the credibility and transparency of data cleaning and analysis is increasingly important.


"Good" code has two elements:
- it is correct (doesn't produce any errors along the way)
- it is useful and comprehensible to someone who hasn't seen it before (including the author three weeks later)
Many researchers have been trained to code correctly. 
However, when your code runs on your computer and you get the correct results, you are only half-done writing \underline{good} code.
Good code is easy to read and replicate, making it easier to spot mistakes.
Good code reduces noise due to sampling, randomization, and cleaning errors.
Good code can easily be reviewed by others before it's published and replicated afterwards.

Process standardization means that there is
little ambiguity about how something ought to be done,
and therefore the tools to do it can be set in advance.
Standard processes for code help other people to ready your code.\sidenote{
\url{https://dimewiki.worldbank.org/wiki/Stata_Coding_Practices}} 
Code should be well-documented, contain extensive comments, and be readable in the sense that others can:
(1) quickly understand what a portion of code is supposed to be doing;
(2) evaluate whether or not it does that thing correctly; and
(3) modify it efficiently either to test alternative hypotheses
or to adapt into their own work.\sidenote{\url{https://kbroman.org/Tools4RR/assets/lectures/07_clearcode.pdf}}

To accomplish that, you should think of code in terms of three major elements:
\textbf{structure}, \textbf{syntax}, and \textbf{style}.
We always tell people to "code as if a stranger would read it"
(from tomorrow, that stranger will be you).
The \textbf{structure} is the environment your code lives in:
good structure means that it is easy to find individual pieces of code that correspond to tasks.
Good structure also means that functional blocks are sufficiently independent from each other
that they can be shuffled around, repurposed, and even deleted without damaging other portions.
The \textbf{syntax} is the literal language of your code.
Good syntax means that your code is readable
in terms of how its mechanics implement ideas --
it should not require arcane reverse-engineering
to figure out what a code chunk is trying to do.
\textbf{Style}, finally, is the way that the non-functional elements of your code convey its purpose.
Elements like spacing, indentation, and naming (or lack thereof) can make your code much more 
(or much less) accessible to someone who is reading it for the first time and needs to understand it quickly and correctly.

For some implementation portions where precise code is particularly important,
we will provide minimal code examples either in the book or on the DIME Wiki.
In the book, they will be presented like the following:

\codeexample{code.do}{./code/code.do}

For the code examples, we ensure that each block runs, is well-formatted, and uses built-in functions as much as possible.
We will point to user-written functions when they provide important tools.
In particular, we point to two suites of Stata commands developed by DIME Analytics,
\texttt{ietoolkit}\sidenote{\url{https://dimewiki.worldbank.org/wiki/ietoolkit}} and \texttt{iefieldkit},\sidenote{\url{https://dimewiki.worldbank.org/wiki/iefieldkit}},
which standardize our core data collection workflows.
We do not explain Stata commands unless the behavior we are exploiting
is outside the usual expectation of its functionality;
we will comment the code generously (as you should),
but you should reference Stata help-files \texttt{h [command]}
whenever you do not understand the functionality that is being used.
We hope that these snippets will provide a foundation for your code style.
Providing some standardization to Stata code style is also a goal of this team,
we provide our guidance on this in the DIME Analytics Stata Style Guide Appendix. 


While adopting the workflows and mindsets described in this book
requires an up-front cost,
it should start to save yourself and others a lot of time and hassle very quickly.
In part this is because you will learn how to implement essential practices directly;
in part because you will find tools for the more advanced practices;
and most importantly because you will acquire the mindset of doing research with a high-quality data focus.
We hope you will find this book helpful for accomplishing all of the above,
and that mastery of data helps you make an impact!

\textbf{-- The DIME Analytics Team}

\mainmatter
