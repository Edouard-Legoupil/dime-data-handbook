%------------------------------------------------

\begin{fullwidth}
Development research does not just \textit{involve} real people -- it also \textit{affects} real people.
Policy decisions are made every day using the results of briefs and studies,
and these can have wide-reaching consequences on the lives of millions.
As the range and importance of the policy-relevant questions
asked by development researchers grow,
so does the (rightful) scrutiny under which methods and results are placed.
This scrutiny involves two major components: data handling and analytical quality.
Performing at a high standard in both means that
consumers of research can have confidence in its conclusions,
and that research participants are appropriately protected.
What we call ethical standards in this chapter is a set of practices
for research quality and data privacy that address these two principles.

Neither quality nor privacy is an ``all-or-nothing'' objective.
We expect that teams will do as much as they can to make their work
conform to modern practices of credibility, transparency, and reproducibility.
Similarly, we expect that teams will ensure the privacy of participants in research
by intelligently assessing and proactively averting risks they might face.
We also expect teams will report what they have and have not done
in order to provide objective measures of a research product's performance in both.
Otherwise, reputation is the primary signal for the quality of evidence, and two failures may occur:
low-quality studies from reputable sources may be used as evidence when in fact they don't warrant it,
and high-quality studies from sources without an international reputation may be ignored.
Both these outcomes reduce the quality of evidence overall.
Even more importantly, they usually mean that credibility in development research accumulates at international institutions
and top global universities instead of the people and places directly involved in and affected by it.
Simple transparency standards mean that it is easier to judge research quality,
and making high-quality research identifiable also increases its impact.
This section provides some basic guidelines and resources
for using field data ethically and responsibly to publish research findings.
\end{fullwidth}

%------------------------------------------------

\section{Protecting confidence in development research}

The empirical revolution in development research
\index{transparency}\index{credibility}\index{reproducibility}
has led to increased public scrutiny of the reliability of research.\cite{rogers_2017}
Three major components make up this scrutiny: \textbf{reproducibility}.\cite{duvendack2017meant}, \textbf{transparency},\cite{christensen2018transparency} and \textbf{credibility},\cite{ioannidis2017power}.
Reproducibility is one key component of transparency.
Transparency is necessary for consumers of research products
to be able to determine the quality of the research process and the value of the evidence.
Without it, all evidence of credibility comes from reputation,
and it's unclear what that reputation is based on, since it's not transparent.

Development researchers should take these concerns particularly seriously.
Many development research projects are purpose-built to address specific questions,
and often use unique data or small samples.
This approach opens the door to working closely with the broader development community
to answer specific programmatic questions and general research inquiries.
However, almost by definition,
primary data that researchers use for such studies has never been reviewed by anyone else,
so it is hard for others to verify that it was collected, handled, and analyzed appropriately.
Maintaining confidence in research via the components of credibility, transparency, and reproducibility
is the most important way that researchers using primary data can avoid serious error,
and therefore these are not by-products but core components of research output.

\subsection{Research reproducibility}

Reproducible research means that the actual analytical processes you used are executable by others.\cite{dafoe2014science}
(We use ``reproducibility'' to refer to the code processes in a specific study.\sidenote{\url{http://datacolada.org/76}})
All your code files involving data cleaning, construction and analysis
should be public (unless they contain identifying information).
Nobody should have to guess what exactly comprises a given index,
or what controls are included in your main regression,
or whether or not you clustered standard errors correctly.
That is, as a purely technical matter, nobody should have to ``just trust you'',
nor should they have to bother you to find out what happens
if any or all of these things were to be done slightly differently.\cite{simmons2011false,wicherts2016degrees}
Letting people play around with your data and code is a great way to have new questions asked and answered
based on the valuable work you have already done.
Services like GitHub that expose your code development process are valuable resources here.
They can show things like modifications made in response to referee comments.
They can also document the research paths and questions you may have tried to answer
(but excluded from publication)
as a resource to others who have similar questions of their own data.

Secondly, reproducible research\sidenote{\url{https://dimewiki.worldbank.org/wiki/Reproducible_Research}}
enables other researchers to re-use your code and processes
to do their own work more easily and effectively in the future.
This may mean applying your techniques to their data
or implementing a similar structure in a different context.
As a pure public good, this is nearly costless.
The useful tools and standards you create will have high value to others.
If you are personally or professionally motivated by citations,
producing these kinds of resources can lead to that as well.
Therefore, your code should be written neatly with clear instructions and published openly.
It should be easy to read and understand in terms of structure, style, and syntax.
Finally, the corresponding dataset should be openly accessible
unless for legal or ethical reasons it cannot be.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Publishing_Data}}

\subsection{Research transparency}

Transparent research will expose not only the code,
but all the processes involved in establishing credibility to the public.\sidenote{\url{http://www.princeton.edu/~mjs3/open_and_reproducible_opr_2017.pdf}}
This means that readers be able to judge for themselves if the research was done well,
and if the decision-making process was sound.
If the research is well-structured, and all relevant documentation\sidenote{\url{https://dimewiki.worldbank.org/wiki/Data_Documentation}} is shared,
this makes it as easy as possible for the reader to implement.
This is also an incentive for researchers to make better decisions,
be skeptical and thorough about their assumptions,
and, as we hope to convince you, make the process easier for themselves,
because it requires methodical organization that is labor-saving and efficient over the complete course of a project.

\textbf{Registered Reports}\sidenote{\url{https://blogs.worldbank.org/impactevaluations/registered-reports-piloting-pre-results-review-process-journal-development-economics}} can help with this process where available.
By setting up a large portion of the research design in advance,\sidenote{\url{https://www.bitss.org/2019/04/18/better-pre-analysis-plans-through-design-declaration-and-diagnosis/}}
a great deal of work has already been completed,
and at least some research questions are pre-committed for publication regardless of the outcome.
This is meant to combat the ``file-drawer problem'',\cite{simonsohn2014p}
and ensure that researchers are transparent in the additional sense that
all the results obtained from registered studies are actually published.

Documenting a project in detail greatly increases transparency.
This means explicitly noting decisions as they are made, and explaining the process behind them.
Documentation on data processing and additional hypotheses tested will be expected in the supplemental materials to any publication.
Careful documentation will also save the research team a lot of time during a project,
as it prevents you to have the same discussion twice (or more!),
since you have a record of why something was done in a particular way.
There are a number of available tools
that will contribute to producing documentation,
\index{project documentation}
but project documentation should always be an active and ongoing process,
not a one-time requirement or retrospective task.
New decisions are always being made as the plan begins contact with reality,
and there is nothing wrong with sensible adaptation so long as it is recorded and disclosed.
(Email is \texttt{not} a note-taking service.)

There are various software solutions for building documentation over time.
The \textbf{Open Science Framework}\sidenote{\url{https://osf.io/}} provides one such solution,
with integrated file storage, version histories, and collaborative wiki pages.
\textbf{GitHub}\sidenote{\url{https://github.com}} provides a transparent documentation system,\sidenote{\url{https://dimewiki.worldbank.org/wiki/Getting_started_with_GitHub}}
\index{task management}\index{GitHub}
in addition to version histories and wiki pages.
It offers multiple different ways to record the decision process leading to changes and additions,
track and register discussions, and manage tasks.
It's a flexible tool that can be adapted to different team and project dynamics,
but is less effective for file storage.
Each project has its specificities,
and the exact shape of this process can be molded to the team's needs,
but it should be agreed upon prior to project launch.
This way, you can start building a project's documentation as soon as you start making decisions.

\subsection{Research credibility}

The credibility of research is traditionally a function of design choices.\cite{angrist2010credibility,ioannidis2005most}
Is the research design sufficiently powered through its sampling and randomization?
Were the key research outcomes pre-specified or chosen ex-post?
How sensitive are the results to changes in specifications or definitions?
Tools such as \textbf{pre-analysis plans}\sidenote{\url{https://dimewiki.worldbank.org/wiki/Pre-Analysis_Plan}}
can be used to assuage these concerns for experimental evaluations
\index{pre-analysis plan}
by fully specifying some set of analysis intended to be conducted,
but they may feel like ``golden handcuffs'' for other types of research.\cite{olken2015promises}
Regardless of whether or not a formal pre-analysis plan is utilized,
all experimental and observational studies should be \textbf{pre-registered}\sidenote{
	\url{https://dimewiki.worldbank.org/wiki/Pre-Registration}}
simply to create a record of the fact that the study was undertaken.
This is increasingly required by publishers and can be done very quickly
using the \textbf{AEA} database,\sidenote{\url{https://www.socialscienceregistry.org/}}
the \textbf{3ie} database,\sidenote{\url{http://ridie.3ieimpact.org/}},
the \textbf{eGAP} database,\sidenote{\url{http://egap.org/content/registration/}},
or the \textbf{OSF} registry\sidenote{\url{https://osf.io/registries}} as appropriate.\sidenote{\url{http://datacolada.org/12}}
\index{pre-registration}

With the rise of empirical research and increased public scrutiny of scientific evidence, however,
this is no longer enough to guarantee that findings will hold their credibility.
Even if your methods are highly precise,
your evidence is just as good as your data,
and there are plenty of mistakes that can be made between establishing a design and generating final results that would compromise its conclusions.
That is why transparency is key for research credibility.
It allows other researchers, and research consumers,
to verify the steps to a conclusion by themselves,
and decide whether their standards for accepting a finding as evidence are met.


%------------------------------------------------

\section{Ensuring privacy and security in research}

Anytime you are collecting primary data in a development research project,\index{primary data}
you are almost certainly handling data that include \textbf{personally-identifying information (PII)}.\sidenote{\textbf{Personally-identifying information:}
	any piece or set of information that can be used to identify an individual research subject.
	\url{https://dimewiki.worldbank.org/wiki/De-identification\#Personally\_Identifiable\_Information}}
\index{personally-identifying information}
PII data contains information that can, without any transformation, be used to identify
individual people, households, villages, or firms that were included in \textbf{data collection}.
\index{data collection}
This includes names, addresses, and geolocations, and extends to personal information
\index{geodata}
such as email addresses, phone numbers, and financial information.
\index{de-identification}
It is important to keep in mind these data privacy principles not only for the individual respondent but also the PII data of their household members or other caregivers who are covered under the survey.
In some contexts this list may be more extensive --
for example, if you are working in a small environment,
someone's age and gender may be sufficient to identify them
even though these would not be considered PII in a larger context.
Therefore you will have to use careful judgment in each case
to decide which pieces of information fall into this category.\sidenote{
	\url{https://sdcpractice.readthedocs.io/en/latest/}}

Most of the field research done in development involves human subjects.\sidenote{
\url{https://dimewiki.worldbank.org/wiki/Human_Subjects_Approval}}
\index{human subjects}
As a researcher, you are asking people to trust you with personal information about themselves:
where they live, how rich they are, whether they have committed or been victims of crimes,
their names, their national identity numbers, and all sorts of other data.
PII data carries strict expectations about data storage and handling,
and it is the responsibility of the research team to satisfy these expectations.\sidenote{
\url{https://dimewiki.worldbank.org/wiki/Research_Ethics}}
Your donor or employer will most likely require you to hold a certification from a source
such as Protecting Human Research Participants\sidenote{
\url{https://humansubjects.nih.gov/sites/hs/phrp/PHRP_Archived_Course_Materials.pdf}}
or the CITI Program.\sidenote{
\url{https://about.citiprogram.org/en/series/human-subjects-research-hsr/}}

Raw data which contains PII \textit{must} be \textbf{encrypted}\sidenote{\url{https://dimewiki.worldbank.org/wiki/encryption}}
\index{encryption}
during data collection, storage, and transfer.
\index{data transfer}\index{data storage}
Most modern data collection software has features that, if enabled, make the first part straightforward.\sidenote{\url{https://dimewiki.worldbank.org/wiki/SurveyCTO_Form_Settings}}
However, secure storage and transfer are your responsibility.\sidenote{\url{https://dimewiki.worldbank.org/wiki/Data_Security}}
There are plenty of options available to keep your data safe,
at different prices, from enterprise-grade solutions to combined free options.
You will also want to setup a password manager that allows you to share encryption keys inside your team.
These will vary in level of security and ease of use,
and sticking to a standard practice will make your life easier,
so agreeing on a protocol from the start of a project is ideal.

In general, though, you shouldn't need to handle PII data very often.
Once data is securely collected and stored, the first thing you will generally do is \textbf{de-identify} it.\sidenote{\url{https://dimewiki.worldbank.org/wiki/De-identification}}
\index{de-identification}
De-identified data should avoid, for example, you being sent back to every household
to alert them that someone dropped all their personal information on a public bus and we don't know who has it.
This simply means creating a copy of the data that contains no personally-identifiable information.
This data should be an exact copy of the raw data,
except it would be okay for it to be publicly released.\cite{matthews2011data}
Ideally, all machines used to store and process PII data are not only password protected, but also encrypted at the hard drive level
(most modern operating systems provide such a tool).
This means that even if you lose your computer with identifying data in it,
anyone who gets hold of it still cannot access the information.
